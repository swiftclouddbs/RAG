{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912fea65-c11b-479c-9ba9-d7c25977b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srstuartii\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (2016server). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Adapted from vendor code:  https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb\n",
    "\n",
    "## Loads text docs into Chroma vector store\n",
    "## Catalog of document loaders is here:  https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "#from langchain_community.document_loaders import TextLoader\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "#import chromadb\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "import gpt4all\n",
    "\n",
    "#Set llm\n",
    "local_llm = \"llama3.1\"\n",
    "\n",
    "#ID directory to persist data\n",
    "#client = chromadb.PersistentClient(path=\"/Users/reginaldstuart/Documents/IT/ML:AI/myRAG/chroma_db\")\n",
    "\n",
    "#create chroma_client and connect to server.  \n",
    "#chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "\n",
    "#Select files we want to input\n",
    "files = [\n",
    "    \"Flight_Training_Guide.pdf\",\n",
    "]\n",
    "\n",
    "#Load files\n",
    "docs = [PyPDFLoader(file).load() for file in files]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "#Split files\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "\n",
    "\n",
    "#Here is the data we want to load\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"test_col_1\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    "#    embedding=embedding_functions.DefaultEmbeddingFunction(),\n",
    "#    embedding=SentenceTransformerEmbeddings(),\n",
    "    persist_directory=\"./ccbc_rag_db_2\",\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "##Now you should be able to read the vectorstore from another window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906a21ff-feca-43da-b38a-1c340eccb13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srstuartii\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 0.4. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fly for a major airline, you typically need an Airline Transport Pilot (ATP) license. This is the highest level of licensure in the United States and is required by the Federal Aviation Administration (FAA). The ATP license requires a minimum of 1,500 hours of flight time, including 500 hours of cross-country flight time and 100 hours of night flight time. Additionally, you must be at least 23 years old and have a high school diploma or equivalent. You also need to pass a written exam and a practical test (checkride) with an FAA inspector.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use ten sentences maximum <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "#     Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "#     Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "#     Question: {question} \n",
    "#     Context: {context} \n",
    "#     Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "#     input_variables=[\"question\", \"document\"],\n",
    "# )\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"what types of aircraft can we get a license for?\"\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58855cde-94c0-4851-929a-78fdadc628ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
