{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ff0f0f-2e17-49d9-b7eb-14a5ab36e21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the text, one of the intentions behind preparing the Guti√©rrez map was \"to define clearly Spain\\'s America for the other European powers who might have designs on the region.\" This suggests that the map was intended to assert Spanish claims and territory in the Americas.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "#from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "#from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# See full prompt at https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# # Prompt\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "#     Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "#     Use ten sentences maximum <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "#     Question: {question} \n",
    "#     Context: {context} \n",
    "#     Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "#     input_variables=[\"question\", \"document\"],\n",
    "# )\n",
    "\n",
    "\n",
    "# Connect to the ChromaDB client\n",
    "client = chromadb.Client()  # Replace with your ChromaDB path\n",
    "\n",
    "# Create embeddings\n",
    "embedding_model = NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\")\n",
    "\n",
    "# Load the Chroma collection\n",
    "collection_name = \"America\"\n",
    "\n",
    "# Specify the directory where the Chroma vector data is stored\n",
    "PERSIST_DIRECTORY = \"./persist_nov_22_b\"  # Update with your directory path\n",
    "\n",
    "# Connect to your Chroma database (vector store) with persistence\n",
    "vectorstore = Chroma(\n",
    "    collection_name=collection_name, \n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=PERSIST_DIRECTORY  # Specify persistent directory\n",
    ")\n",
    "\n",
    "# # Create the LLM\n",
    "llm = Ollama(model=\"llama3.1\")\n",
    "\n",
    "# def format_docs(docs):\n",
    "#     return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vectorstore.as_retriever(), #| format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "qa_chain.invoke(\"what does it say about Spain?\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bfeb3-41f7-4487-83d4-6138b91b76f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
